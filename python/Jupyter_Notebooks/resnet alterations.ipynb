{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6b7159f-e211-4b11-bd74-b17ba1e4a156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Archiv\\Studium\\Master\\6.-Semester\\Masters_Thesis\\Git\\acoustic_covid_detection\\python\n"
     ]
    }
   ],
   "source": [
    "from jupyter_utils import jupyter_setup\n",
    "jupyter_setup()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import resnet18, resnet50, ResNet18_Weights, ResNet50_Weights\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.nn import InstanceNorm2d\n",
    "from utils.utils import ResidualInstanceNorm2d\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ae7bb7-1b10-443a-98f9-95d414848b0a",
   "metadata": {},
   "source": [
    "# Set the learning rate for each layer\n",
    "For transfer learning/fine tuning it is advantageous if the model retains most of the learned parameters in the early layers (more abstract representations like shapes). This can be achieved by setting the lr very small for early layers and higher for later layers. The extreme of that would be to freeze some layers (or all except for the classification layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f8569ad-13a8-4c30-8c63-1ddca6f3a3f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_parameter_groups(model, output_lr, input_lr, weight_decay=1e-4, verbose=True):\n",
    "    # applies different learning rates for each (parent) layer in the model (for finetuning a pretrained network).\n",
    "    # the inout layer gets the input_lr, the output layer the output_lr. All layers in between get linearly interpolated.\n",
    "\n",
    "    # works for resnet architecture and assigns a learning rate for each parent layer and the input and output layers\n",
    "    # in total there are (for a resnet 18) 61 parameter groups but only 4 parent layers and 3 layers as input/output layers\n",
    "    # this means there are only  4+3  different learning rates.\n",
    "    \n",
    "    parent_layer = lambda name: name.split(\".\")[0]    \n",
    "    layer_names = [name for name, _ in model.named_parameters()]\n",
    "    layer_names.reverse()\n",
    "    parent_layers = list(set([parent_layer(layer) for layer in layer_names]))\n",
    "    n_parent_layers = len(parent_layers)\n",
    "    lr=output_lr\n",
    "    last_parent_layer = parent_layer(layer_names[0])\n",
    "    if verbose:\n",
    "        print(f'0: lr = {lr:.6f}, {last_parent_layer}')\n",
    "    \n",
    "    lr_mult = np.power(input_lr/output_lr, 1/(n_parent_layers-1))\n",
    "    parameters = []\n",
    "    for idx, layer in enumerate(layer_names):\n",
    "        current_parent_layer = parent_layer(layer)\n",
    "        if last_parent_layer != (current_parent_layer):\n",
    "            lr *= lr_mult\n",
    "            if verbose:\n",
    "                print(f'{idx}: lr = {lr:.6f}, {current_parent_layer}')\n",
    "            last_parent_layer = current_parent_layer\n",
    "        parameters.append({'params': [p for n, p in model.named_parameters() if n == layer and p.requires_grad],\n",
    "                           'lr':     lr,\n",
    "                           'weight_decay': weight_decay})\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4e500b4-43fb-4714-9329-e623863279ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_model = resnet18(weights=ResNet18_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18196ca6-e0ea-4d4a-a3ba-7e1f54f65115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: lr = 0.001000, fc\n",
      "2: lr = 0.000607, layer4\n",
      "17: lr = 0.000368, layer3\n",
      "32: lr = 0.000224, layer2\n",
      "47: lr = 0.000136, layer1\n",
      "59: lr = 0.000082, bn1\n",
      "61: lr = 0.000050, conv1\n"
     ]
    }
   ],
   "source": [
    "parameters = get_parameter_groups(my_model, output_lr=1e-3, input_lr=5e-5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e5c961f-7110-4d6f-a8d0-4a5a060b630c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(parameters)\n",
    "lr_scheduler = ExponentialLR(optimizer, gamma=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaabfb9-2192-4a08-a0e0-d2afbc341a4b",
   "metadata": {},
   "source": [
    "# Change the number of input channels\n",
    "The pretrained resnet was trained on RGB images. Hence it has 3 input channels, for each color 1. I only have 1 channel, so what to do with the pretrained weights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c4aa52bb-c4ad-4cea-b986-d3118bc8e16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a single channel that has the mean of the 3 RGB channel weights\n",
    "weights_single_channel = weights.mean(dim=1).unsqueeze(dim=1)\n",
    "# create a single channel that has the channel weights of channel 0 (red channel i guess)\n",
    "weights_single_color = weights[:, 0, :, :].unsqueeze(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23ccfbce-d8eb-4794-9939-0b2d2f4ef341",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.conv1 = nn.Conv2d(in_channels=1, out_channels=64 , kernel_size=7, stride=2, padding=3, bias=False)\n",
    "my_model.conv1.weight = nn.Parameter(weights_single_channel)\n",
    "# my_model.conv1.weight = nn.Parameter(weights_single_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e719c62-c4fb-4695-a3a4-36d12da9a778",
   "metadata": {},
   "source": [
    "# add dropout after each parent layer in resnet (everytime downsampling is applied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5d9beed-f4b7-4e60-b741-108c82590b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = resnet18(weights=ResNet18_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5172b27f-b738-4c8f-97e0-ff7805b268b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.layer1 = nn.Sequential(*my_model.layer1, nn.Dropout2d(p=0.1))\n",
    "my_model.layer2 = nn.Sequential(*my_model.layer2, nn.Dropout2d(p=0.2))\n",
    "my_model.layer3 = nn.Sequential(*my_model.layer3, nn.Dropout2d(p=0.3))\n",
    "my_model.layer4 = nn.Sequential(*my_model.layer4, nn.Dropout2d(p=0.4))\n",
    "my_model.avgpool = nn.Sequential(my_model.avgpool, nn.Dropout(p=0.5))\n",
    "# my_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (python_v3-8)",
   "language": "python",
   "name": "python_v3-8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
