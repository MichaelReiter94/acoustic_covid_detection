{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "99ebdcba-c628-4beb-aac8-4091d0007f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Archiv\\Studium\\Master\\6.-Semester\\Masters_Thesis\\Git\\acoustic_covid_detection\\python\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from jupyter_utils import jupyter_setup, load_tracker\n",
    "import ipywidgets as widgets\n",
    "jupyter_setup()\n",
    "# from torchvision.models import resnet18, resnet50, ResNet18_Weights, ResNet50_Weights\n",
    "from models import get_resnet18\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fce7da14-a1c7-4dc0-b8e6-1f3aaaaafbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = get_resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce2d5fa4-fc6a-46e4-9733-b7c89023a9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bag_statistics(y, batch_size, bag_size):\n",
    "    y = y.view(batch_size, bag_size)\n",
    "    \n",
    "    mu = y.mean(dim=1)\n",
    "    diff = y.t() - mu\n",
    "    sigma = torch.pow(torch.mean(torch.pow(diff, 2.0), dim=0), 0.5)\n",
    "    z_scores = diff / sigma\n",
    "    skew = torch.mean(torch.pow(z_scores, 3), dim=0)\n",
    "    kurtoses = torch.mean(torch.pow(z_scores, 4), dim=0)\n",
    "    median, _ = y.median(dim=1)\n",
    "    minimum, _ = y.min(dim=1)\n",
    "    maximum, _ = y.max(dim=1)\n",
    "\n",
    "    bag_statistics = torch.stack([mu, median, sigma, minimum, maximum, skew, kurtoses]).t()\n",
    "    return bag_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3e5f9137-f7f3-4aab-8830-6e2edf09a8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionLevelMIL_SingleGatedLayer(nn.Module):\n",
    "    def __init__(self, n_neurons, dropout=0.25):\n",
    "        super().__init__()\n",
    "        self.n_bag_statistics = 7\n",
    "        self.n_hidden_attention = n_neurons\n",
    "        self.dropout = dropout\n",
    "        self.resnet_out_features = 512\n",
    "        \n",
    "        self.binary_classification_layer = nn.Sequential(\n",
    "            nn.Linear(self.resnet_out_features, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.attention_V = nn.Sequential(\n",
    "            nn.Linear(self.n_bag_statistics, self.n_hidden_attention),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        self.attention_U = nn.Sequential(\n",
    "            nn.Linear(self.n_bag_statistics, self.n_hidden_attention),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        self.attention_out =  nn.Sequential(\n",
    "            nn.Dropout(p=self.dropout),\n",
    "            nn.Linear(self.n_hidden_attention, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, y, batch_size, bag_size):\n",
    "        y = self.binary_classification_layer(y.squeeze())\n",
    "        bag_statistics = get_bag_statistics(y, batch_size, bag_size)\n",
    "        A_V = self.attention_V(bag_statistics)\n",
    "        A_U = self.attention_U(bag_statistics)\n",
    "        y_pred = self.attention_out(A_V * A_U)  # element wise multiplication\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "de45b3dc-d6bf-44d9-87d3-f5334bf21a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionLevelMIL_DoubleDenseLayer(nn.Module):\n",
    "    def __init__(self, n_neurons, dropout=0.25):\n",
    "        super().__init__()\n",
    "        self.n_bag_statistics = 7\n",
    "        self.n_hidden_attention = n_neurons\n",
    "        self.dropout = dropout\n",
    "        self.resnet_out_features = 512\n",
    "        \n",
    "        self.binary_classification_layer = nn.Sequential(\n",
    "            nn.Linear(self.resnet_out_features, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.mil_net =  nn.Sequential(\n",
    "            nn.Linear(self.n_bag_statistics, self.n_hidden_attention),\n",
    "            nn.Dropout(p=self.dropout),\n",
    "            nn.Linear(self.n_hidden_attention, self.n_hidden_attention),\n",
    "            nn.Dropout(p=self.dropout),\n",
    "            nn.Linear(self.n_hidden_attention, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, y, batch_size, bag_size):\n",
    "        y = self.binary_classification_layer(y.squeeze())\n",
    "        bag_statistics = get_bag_statistics(y, batch_size, bag_size)\n",
    "        y_pred = self.mil_net(bag_statistics)  # element wise multiplication\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7a3fdfd8-61a7-48f0-b496-d02b982708af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureLevelMIL(nn.Module):\n",
    "    def __init__(self, n_neurons, dropout=0.25):\n",
    "        super().__init__()\n",
    "        self.n_hidden_attention = n_neurons\n",
    "        self.dropout = dropout\n",
    "        self.resnet_out_features = 512\n",
    "#         self.n_features = n_features\n",
    "        \n",
    "#         self.feature_layer = nn.Sequential(\n",
    "#             nn.Linear(self.resnet_out_features, n_features),\n",
    "#         )\n",
    "        \n",
    "        self.attention_V = nn.Sequential(\n",
    "            nn.Linear(self.resnet_out_features, self.n_hidden_attention),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        self.attention_U = nn.Sequential(\n",
    "            nn.Linear(self.resnet_out_features, self.n_hidden_attention),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        self.attention_out =  nn.Sequential(\n",
    "            nn.Dropout(p=self.dropout),\n",
    "            nn.Linear(self.n_hidden_attention, 1)\n",
    "        )\n",
    "        \n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(in_features=self.resnet_out_features, out_features=1)\n",
    "            # nn.Linear(in_features=128, out_features=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, y, batch_size, bag_size):\n",
    "        # y = self.feature_layer(y.squeeze())\n",
    "        \n",
    "        y = y.squeeze()\n",
    "        # batchsize*bagsize x 512\n",
    "\n",
    "        A_V = self.attention_V(y)\n",
    "        A_U = self.attention_U(y)\n",
    "        attentation_coef = self.attention_out(A_V * A_U)  # element wise multiplication\n",
    "        attentation_coef = attentation_coef.view(batch_size, bag_size, 1)\n",
    "        attentation_coef = F.softmax(attentation_coef, dim=1)\n",
    "        # batchsize x bagsize x 1\n",
    "        \n",
    "        x_combined_bag = y.view(batch_size, bag_size, self.resnet_out_features) * attentation_coef\n",
    "        # y = y.view(batch_size, bag_size, 1)\n",
    "        # [batchsize x bagsize x 512] * [batchsize x bagsize x 1]\n",
    "        x_combined_bag = x_combined_bag.mean(dim=1)\n",
    "        # [batch_size x 512]\n",
    "        y_pred = self.output_layer(x_combined_bag)\n",
    "        # [batch_size x 1]\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "465f363a-819f-4ee2-a836-aca1cb94e212",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureLevelMIL_ExtraFeatureLayer(nn.Module):\n",
    "    def __init__(self, n_features, n_neurons, dropout=0.25):\n",
    "        super().__init__()\n",
    "        self.n_hidden_attention = n_neurons\n",
    "        self.dropout = dropout\n",
    "        self.resnet_out_features = 512\n",
    "        self.n_features = n_features\n",
    "        \n",
    "        self.feature_layer = nn.Sequential(\n",
    "            nn.Linear(self.resnet_out_features, self.n_features),\n",
    "            nn.Dropout(p=self.dropout)\n",
    "        )\n",
    "        \n",
    "        self.attention_V = nn.Sequential(\n",
    "            nn.Linear(self.n_features, self.n_hidden_attention),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        self.attention_U = nn.Sequential(\n",
    "            nn.Linear(self.n_features, self.n_hidden_attention),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        self.attention_out =  nn.Sequential(\n",
    "            nn.Dropout(p=self.dropout),\n",
    "            nn.Linear(self.n_hidden_attention, 1)\n",
    "        )\n",
    "        \n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(self.n_features, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, y, batch_size, bag_size):\n",
    "        # y = self.feature_layer(y.squeeze())\n",
    "        \n",
    "        y = self.feature_layer(y.squeeze())\n",
    "        # batchsize*bagsize x 512\n",
    "\n",
    "        A_V = self.attention_V(y)\n",
    "        A_U = self.attention_U(y)\n",
    "        attentation_coef = self.attention_out(A_V * A_U)  # element wise multiplication\n",
    "        attentation_coef = attentation_coef.view(batch_size, bag_size, 1)\n",
    "        attentation_coef = F.softmax(attentation_coef, dim=1)\n",
    "        # batchsize x bagsize x 1\n",
    "        \n",
    "        x_combined_bag = y.view(batch_size, bag_size, self.n_features) * attentation_coef\n",
    "        # y = y.view(batch_size, bag_size, 1)\n",
    "        # [batchsize x bagsize x 512] * [batchsize x bagsize x 1]\n",
    "        x_combined_bag = x_combined_bag.mean(dim=1)\n",
    "        # [batch_size x 512]\n",
    "        y_pred = self.output_layer(x_combined_bag)\n",
    "        # [batch_size x 1]\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b428200a-f0c9-4168-83b0-320ecda294c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "newmodel = torch.nn.Sequential(*(list(resnet.children())[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6e708372-0fd4-42cc-93c9-f07c9a96642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mil = PredictionLevelMIL_SingleGatedLayer(32)\n",
    "# mil = PredictionLevelMIL_SingleGatedLayer(32)\n",
    "# mil = FeatureLevelMIL(32)\n",
    "mil = FeatureLevelMIL_ExtraFeatureLayer(64, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "81f1d53e-bb95-4fb5-8b15-a54ce5ee7985",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(16, 8, 1, 224, 112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6bbe655f-f846-4d7a-9a7c-a15574305edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, bag_size = x.shape[0], x.shape[1]\n",
    "feature_size = x.shape[2:]\n",
    "x = x.view(batch_size * bag_size, *feature_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f7aa8a00-518b-4ef0-a9fd-830f9c53edc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 512, 1, 1])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = newmodel(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8f1126a0-e32c-454a-905c-ac76f9fab1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = mil(y, batch_size, bag_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "52273736-4fd7-4b7a-870f-e911eca9b75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0581],\n",
       "        [0.0845],\n",
       "        [0.1133],\n",
       "        [0.1208],\n",
       "        [0.0835],\n",
       "        [0.0988],\n",
       "        [0.1136],\n",
       "        [0.0795],\n",
       "        [0.0815],\n",
       "        [0.1122],\n",
       "        [0.0626],\n",
       "        [0.0787],\n",
       "        [0.0939],\n",
       "        [0.0944],\n",
       "        [0.0860],\n",
       "        [0.0855]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2e8131bf-eb91-4b75-8b05-c3782ee5f210",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (python_v3-8)",
   "language": "python",
   "name": "python_v3-8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
