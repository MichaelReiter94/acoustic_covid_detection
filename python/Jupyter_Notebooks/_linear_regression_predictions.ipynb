{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "481d4a51-353d-4f68-92c4-4312083795c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Michi\\acoustic_covid_detection\\python\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from jupyter_utils import jupyter_setup, load_tracker\n",
    "jupyter_setup()\n",
    "import os\n",
    "from evaluation_and_tracking import IDPerformanceTracker\n",
    "import torch\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, precision_recall_curve\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "2bf1c34c-351b-453c-9413-0725c8b0ea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID_PERFORMANCE_TRACKING = \"test_linearRegression.pickle\"\n",
    "ID_PERFORMANCE_TRACKING = \"MILmetadata.pickle\"\n",
    "# ID_PERFORMANCE_TRACKING = \"02_MILDDenseNoMetadata.pickle\"\n",
    "# ID_PERFORMANCE_TRACKING = \"MILDDenseNoMetadata_2epochs.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "4e9e3099-d7ef-41f5-b23f-072ac22a9997",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_performance = IDPerformanceTracker(ID_PERFORMANCE_TRACKING)\n",
    "id_performance.df = id_performance.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "7617b0a2-5c8c-475c-9037-4a64137854b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2888"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "8cc85291-d302-41b2-96e8-69d045d319a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = id_performance.df[id_performance.df.set_type == \"eval\"]\n",
    "test_data = id_performance.df[id_performance.df.set_type == \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "657d7893-83e8-49fd-b626-b114a41f2128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356, 466)"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_ids = eval_data.ID.unique()\n",
    "test_ids = test_data.ID.unique()\n",
    "len(eval_ids), len(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "fd776f7b-1d01-4ce6-b88a-db4d2e593e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['combined_breaths', 'combined_coughs', 'combined_speech',\n",
       "       'combined_vowels'], dtype=object)"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording_types = eval_data.rec_type.unique()\n",
    "recording_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "7488156e-8c24-4a36-8766-b886dea28553",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Participant:\n",
    "    def __init__(self, identifier, df, allow_n_missing_recordings=2):\n",
    "        self.id = identifier\n",
    "        self.cough = self.get_single_prediction(\"combined_coughs\", df)\n",
    "        self.speech = self.get_single_prediction(\"combined_speech\", df)\n",
    "        self.breath = self.get_single_prediction(\"combined_breaths\", df)\n",
    "        self.vowels = self.get_single_prediction(\"combined_vowels\", df)\n",
    "        # try:\n",
    "        self.label = df[df.ID == identifier].label.values[0]\n",
    "        # except IndexError:\n",
    "            # self.label = df[df.ID == identifier].label.values\n",
    "        \n",
    "        no_recording = 0\n",
    "        if self.cough is None:\n",
    "            no_recording += 1\n",
    "            self.cough = 0\n",
    "        if self.speech is None:\n",
    "            no_recording += 1\n",
    "            self.speech = 0\n",
    "        if self.breath is None:\n",
    "            no_recording += 1\n",
    "            self.breath = 0\n",
    "        if self.vowels is None:\n",
    "            no_recording += 1\n",
    "            self.vowels = 0\n",
    "        if no_recording > allow_n_missing_recordings:\n",
    "            raise ValueError(\"there is at least 1 recording not present\")\n",
    "            \n",
    "            \n",
    "        \n",
    "    def get_single_prediction(self, rec_type, df):\n",
    "        idx = np.logical_and(df.ID == self.id, df.rec_type == rec_type)\n",
    "        n_entries = len(df[idx])\n",
    "        if n_entries == 1:\n",
    "            try:\n",
    "                prediction = df[idx].prediction.values[0][-1]\n",
    "            except IndexError:\n",
    "                prediction = df[idx].prediction.values[0]\n",
    "                \n",
    "        elif n_entries == 0:\n",
    "            # print(\"error\")\n",
    "            # raise ValueError(\"No Entry for this\")\n",
    "            # prediction = 0\n",
    "            prediction = None\n",
    "        else:\n",
    "            raise ValueError(\"there cannot be more than one entry with the same ID and rec type\")\n",
    "        # add sigmoid???\n",
    "        # print(prediction)\n",
    "        return prediction\n",
    "    \n",
    "    def get_all_predictions(self):\n",
    "        return np.array([self.cough, self.speech, self.breath, self.vowels])\n",
    "    # def calculate AUCROC, accuracy, loss for one category and after linear regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "5965a12f-ebe9-44cd-9eef-75a99599b87c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10253654, 0.00629406, 0.17058913, 0.16971987])"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "participant = Participant(eval_ids[0], eval_data)\n",
    "participant.get_all_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "a8305e6f-5d69-4b2f-bb7e-ebc2a1e2fe49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_linregr_matrices(eval_ids, data, allow_n_missing_recordings=2):\n",
    "    predictions_matrix = np.array([])\n",
    "    labels = np.array([])\n",
    "    ids = []\n",
    "    for i, participant_id in enumerate(eval_ids):\n",
    "        try:\n",
    "            participant = Participant(participant_id, data, allow_n_missing_recordings=allow_n_missing_recordings)\n",
    "            ids.append(participant_id)\n",
    "        except ValueError:\n",
    "            # print(\"error\")\n",
    "            continue\n",
    "        # print(participant_id)\n",
    "        if i == 0 or len(predictions_matrix) == 0:\n",
    "            predictions_matrix = participant.get_all_predictions()\n",
    "            labels = np.array([participant.label])\n",
    "        else:\n",
    "            predictions = participant.get_all_predictions()\n",
    "            # print(predictions)\n",
    "            predictions_matrix = np.vstack([predictions_matrix, predictions])\n",
    "            labels = np.append(labels, participant.label)\n",
    "        # print(participant_id)\n",
    "    return predictions_matrix, labels, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "1d9493a6-33f4-41d5-8d43-df3a4049f19f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_accuracy(labels, predictions, threshold=0.5, verbose=False):\n",
    "    labels_bool = labels > threshold\n",
    "    # predictions = torch.sigmoid(torch.Tensor(predictions))\n",
    "    predicted_labels = predictions > threshold\n",
    "    n_correctly_predicted = np.sum(predicted_labels == labels_bool) / len(predictions)\n",
    "    return np.round(n_correctly_predicted*100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "8456d629-29b0-4a66-90d8-c96ad7d603c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_aucroc(labels, predictions):\n",
    "    # using mixup, the resulting labels are no longer binary but continous between 0 and 1\n",
    "    # we round to get any kind of result but for the training data, the auc-roc is not quite meaningful\n",
    "    # labels = np.round(self.labels)\n",
    "    # try:\n",
    "    fpr, tpr, thresh = roc_curve(labels, predictions)\n",
    "    aucroc = auc(fpr, tpr)\n",
    "    # except ValueError:\n",
    "    #     # fpr, tpr, thresh = 0, 0, 0\n",
    "    #     aucroc = 0.0\n",
    "    return np.round(aucroc*100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "d0f33e84-4a0a-45b8-b02b-3a1997d13fa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_confusion_matrix_parameters(labels, predictions, threshold=0.5, verbose=False):\n",
    "    predictions_bool = predictions > threshold\n",
    "    labels_bool = labels > threshold\n",
    "    confusion_mat = confusion_matrix(labels_bool, predictions_bool)\n",
    "    mat = np.flip(confusion_mat)\n",
    "    mat = np.concatenate([mat, np.expand_dims(mat.sum(axis=1), 1)], axis=1)\n",
    "    mat = np.concatenate([mat, np.expand_dims(mat.sum(axis=0), 0)], axis=0)\n",
    "    if verbose:\n",
    "        print(\"##########################################################################\\n\")\n",
    "        print(pd.DataFrame(mat, columns=[\"Pred. [+]\", \"Pred. [-]\", \"True Total\"],\n",
    "                           index=[\"True [+]\", \"True [-]\", \"Pred. Total\"]))\n",
    "\n",
    "    # returns parameters in the following order: tn, fp, fn, tp\n",
    "    return confusion_mat.ravel()\n",
    "\n",
    "def get_rates_from_confusion_matrix(confusion_mat, verbose=False):\n",
    "    TN, FP, FN, TP = confusion_mat\n",
    "    total_negatives = TN + FP\n",
    "    total_positives = FN + TP\n",
    "    tpr = round(TP / total_positives, 4)  # also known as recall\n",
    "    tnr = round(TN / total_negatives, 4)\n",
    "    fnr = round(FN / total_positives, 4)\n",
    "    fpr = round(FP / total_negatives, 4)\n",
    "    precision = round(TP / (TP + FP), 4)\n",
    "    if verbose:\n",
    "        print(pd.DataFrame(dict(tpr=tpr * 100, fpr=fpr * 100, tnr=tnr * 100, fnr=fnr * 100), index=[0]))\n",
    "    return tpr, fpr, tnr, fnr, precision\n",
    "\n",
    "def get_auc_prec_recall(labels, predictions):\n",
    "    precision, recall, _ = precision_recall_curve(labels, predictions)\n",
    "    auc_preision_recall = auc(recall, precision)\n",
    "    return auc_preision_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a96a944-3a1f-4ea4-83a5-04af4cdde833",
   "metadata": {},
   "source": [
    "# LINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "49238472-05d3-4c68-996c-f14a0017fb00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigmoid(A):\n",
    "    return torch.sigmoid(torch.Tensor(A)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "ce18eb1f-f4b5-478b-9437-b72c14cf3345",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extend_linregr_matrx(A):\n",
    "    # include further components for the linear regression, like a constant, square of each component, inverse squre, square root,...)\n",
    "    bias = np.ones((A.shape[0], 1))\n",
    "    # sign = np.sign(A)\n",
    "    absolute = np.abs(A)\n",
    "    squares = np.power(A, 2)\n",
    "    cubes = np.power(A, 3)\n",
    "    roots = np.power(absolute, 1/2)\n",
    "    cuberoots = np.power(absolute, 1/3)\n",
    "    power_four = np.power(A, 4)\n",
    "    power_five = np.power(A, 5)\n",
    "    # return np.concatenate((A, squares, roots), axis=1)    \n",
    "    return np.concatenate((A, squares, roots, cubes, cuberoots), axis=1)    \n",
    "    # return np.concatenate((A, bias), axis=1)\n",
    "    # return A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "fac24417-76c1-48f2-bf68-8af55274a168",
   "metadata": {},
   "outputs": [],
   "source": [
    "allow_n_missing_recordings=1\n",
    "A_val, y_val, _ = get_linregr_matrices(eval_ids, eval_data, allow_n_missing_recordings=allow_n_missing_recordings)\n",
    "A_test, y_test, _ = get_linregr_matrices(test_ids, test_data, allow_n_missing_recordings=allow_n_missing_recordings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "aac753ee-0746-4c29-902b-ecccd0165738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275, 453)"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(A_val), len(A_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "c54d78e3-1877-4636-ae6b-5236e70b7048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A_val = sigmoid(A_val)\n",
    "# A_test = sigmoid(A_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "6e29c90b-1aa8-4f0c-b134-1d2191e8cc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_val = extend_linregr_matrx(A_val)\n",
    "A_test = extend_linregr_matrx(A_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "783e46c6-55c3-4adb-95e3-7d2db4e5c290",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(A_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "05d2528e-edd4-4e66-95c7-2dcb9478b240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91.9, 89.1)"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_pred = model.predict(A_val)\n",
    "get_aucroc(y_val, y_val_pred), get_accuracy(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "be371ddf-2593-4510-9b50-109a1c82c8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90.7, 91.4)"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = model.predict(A_test)\n",
    "get_aucroc(y_test, y_test_pred), get_accuracy(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "2ed785fd-8143-481c-a71c-5b9fb8b438ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7.29934299e-03,  7.99226324e-01, -3.19275017e+00, -6.91859464e-01,\n",
       "       -6.58767784e+00, -1.71163058e+00,  1.21738041e+01,  3.27888265e+00,\n",
       "        2.60792534e+00,  1.86393506e+00,  2.31532747e+00,  3.08549001e+00,\n",
       "        1.40546630e+01, -2.84377727e+00, -1.49928849e+01, -3.31409559e+00,\n",
       "       -1.97886512e+00, -1.09455222e+00, -1.41906828e+00, -2.49340813e+00])"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2704e834-e0e5-43cf-a5d9-041046219fe5",
   "metadata": {},
   "source": [
    "# confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "56274d4d-46d6-41b2-8041-50b44998ecff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################################################\n",
      "\n",
      "             Pred. [+]  Pred. [-]  True Total\n",
      "True [+]            77         33         110\n",
      "True [-]            15        231         246\n",
      "Pred. Total         92        264         356\n",
      "    tpr  fpr   tnr   fnr\n",
      "0  70.0  6.1  93.9  30.0\n",
      "\n",
      "precision 83.7\n",
      "\n",
      "F1: 76.2\n",
      "AUC pr-recall: 85.4\n"
     ]
    }
   ],
   "source": [
    "mat = get_confusion_matrix_parameters(y_val, y_val_pred, verbose=True)\n",
    "tpr, _, tnr, _, precision = get_rates_from_confusion_matrix(mat, verbose=True)\n",
    "recall = tpr\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(f\"\\nprecision {round(precision*100, 1)}\")\n",
    "print(f\"\\nF1: {round(f1_score*100, 1)}\")\n",
    "print(f\"AUC pr-recall: {round(get_auc_prec_recall(y_val, y_val_pred)*100, 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "579016c7-4993-4590-ae87-d142d0c3560e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################################################\n",
      "\n",
      "             Pred. [+]  Pred. [-]  True Total\n",
      "True [+]            23         37          60\n",
      "True [-]             4        402         406\n",
      "Pred. Total         27        439         466\n",
      "     tpr   fpr    tnr    fnr\n",
      "0  38.33  0.99  99.01  61.67\n",
      "\n",
      "precision 85.2\n",
      "F1: 52.9\n",
      "AUC pr-recall: 70.1\n"
     ]
    }
   ],
   "source": [
    "mat = get_confusion_matrix_parameters(y_test, y_test_pred, verbose=True)\n",
    "tpr, _, tnr, _, precision = get_rates_from_confusion_matrix(mat, verbose=True)\n",
    "recall = tpr\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(f\"\\nprecision {round(precision*100, 1)}\")\n",
    "print(f\"F1: {round(f1_score*100, 1)}\")\n",
    "print(f\"AUC pr-recall: {round(get_auc_prec_recall(y_test, y_test_pred)*100, 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b73e9bf-2546-4023-becd-d0954eae86ab",
   "metadata": {},
   "source": [
    "# Get perofrmance for a single rec type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "9b99491a-ebb0-4bcc-bf95-dcaadb3f6c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval set:    85.3 31.6\n",
      "test set:    81.3 20.1\n",
      "#################################################\n",
      "eval set:    87.9 77.8\n",
      "test set:    86.6 79.9\n",
      "#################################################\n",
      "eval set:    58.3 22.9\n",
      "test set:    67.8 14.1\n",
      "#################################################\n",
      "eval set:    79.9 33.8\n",
      "test set:    82.6 28.7\n",
      "#################################################\n"
     ]
    }
   ],
   "source": [
    "# AUCROC and accuracy for validation set and test set before linear regression\n",
    "# keep in mind that IDs that were excluded for various reasons (e.g. audio quality) were set to have a prediction right in the middle (0.5) which decreases the performance, especially accuracy\n",
    "for rec_type_idx in range(4): \n",
    "    pred = torch.sigmoid(torch.Tensor(A_val))[:, rec_type_idx].numpy()\n",
    "    print(\"eval set:   \", get_aucroc(y_val, pred), get_accuracy(y_val, pred))\n",
    "    pred = torch.sigmoid(torch.Tensor(A_test))[:, rec_type_idx].numpy()\n",
    "    print(\"test set:   \", get_aucroc(y_test, pred), get_accuracy(y_test, pred))\n",
    "    print(\"#################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "d5387a44-440f-4d43-aee5-0f8ed88b507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rec_type = \"combined_coughs\"\n",
    "# rec_type = \"combined_speech\"\n",
    "rec_type = \"combined_breaths\"\n",
    "# rec_type = \"combined_vowels\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "e20e62f2-26bb-40ff-a5af-3cf1bf1e4511",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_performance = IDPerformanceTracker(ID_PERFORMANCE_TRACKING)\n",
    "id_performance.df = id_performance.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "c6f94cde-426e-455a-afce-af0fb1b75c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['combined_breaths'], dtype=object), 711)"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_performance.df = id_performance.df[id_performance.df.rec_type == rec_type]\n",
    "recording_types = id_performance.df.rec_type.unique()\n",
    "recording_types, len(id_performance.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "dd775463-0c44-4950-8a33-3156e1d88e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(289, 422)"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data = id_performance.df[id_performance.df.set_type == \"eval\"]\n",
    "test_data = id_performance.df[id_performance.df.set_type == \"test\"]\n",
    "eval_ids = eval_data.ID.unique()\n",
    "test_ids = test_data.ID.unique()\n",
    "len(eval_ids), len(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "198c7490-77b2-4d72-aa2a-f476df69b002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['combined_breaths'], dtype=object)"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording_types = test_data.rec_type.unique()\n",
    "recording_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "44fea59a-bf87-4b48-b6a1-ce2e2cc731aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(289, 422)"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_val, y_val, val_ids_filtered = get_linregr_matrices(eval_ids, eval_data, allow_n_missing_recordings=3)\n",
    "A_test, y_test, test_ids_filtered = get_linregr_matrices(test_ids, test_data, allow_n_missing_recordings=3)\n",
    "len(val_ids_filtered), len(test_ids_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "2a1bdd43-d1f2-4493-a769-46ce2a1b3b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_val = extend_linregr_matrx(A_val)\n",
    "A_test = extend_linregr_matrx(A_test)\n",
    "model = LinearRegression().fit(A_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "1c9c7644-eb61-426c-8368-528211032a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92.3, 85.5)"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_pred = model.predict(A_val)\n",
    "get_aucroc(y_val, y_val_pred), get_accuracy(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "4ef4cc42-038e-4617-b0d4-617285be55fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86.5, 92.9)"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = model.predict(A_test)\n",
    "get_aucroc(y_test, y_test_pred), get_accuracy(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "5b7ec3b4-4489-4683-83c8-4f3a45d913ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(422, 422)"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test_pred), len(test_ids_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "6b59aea7-07ce-4e48-b63b-eaa0877cb250",
   "metadata": {},
   "outputs": [],
   "source": [
    "parts_test = [Participant(participant_id, test_data, allow_n_missing_recordings=3) for participant_id in test_ids_filtered]\n",
    "parts_eval = [Participant(participant_id, eval_data, allow_n_missing_recordings=3) for participant_id in val_ids_filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "aa7d817b-2020-4a79-a6e1-6d003b94fae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_preds_test = np.array(torch.sigmoid(torch.Tensor(np.array([part.get_single_prediction(rec_type, test_data) for part in parts_test]))))\n",
    "new_preds_val = np.array(torch.sigmoid(torch.Tensor(np.array([part.get_single_prediction(rec_type, eval_data) for part in parts_eval]))))\n",
    "\n",
    "# preds = [part.get_single_prediction(rec_type, test_data) for part in parts]\n",
    "labels_test = np.array([part.label for part in parts_test])\n",
    "labels_eval = np.array([part.label for part in parts_eval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "c4cf4da5-b436-424b-a942-3812230ff916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3\n",
      "85.9  |  75.7\n",
      "-0.2923076923076923\n",
      "85.9  |  75.7\n",
      "-0.2846153846153846\n",
      "85.9  |  75.7\n",
      "-0.27692307692307694\n",
      "85.9  |  75.7\n",
      "-0.2692307692307692\n",
      "85.9  |  75.7\n",
      "-0.26153846153846155\n",
      "85.9  |  75.7\n",
      "-0.25384615384615383\n",
      "85.9  |  75.7\n",
      "-0.24615384615384614\n",
      "85.9  |  75.7\n",
      "-0.23846153846153845\n",
      "85.9  |  75.7\n",
      "-0.23076923076923078\n",
      "85.9  |  75.7\n",
      "-0.22307692307692306\n",
      "85.9  |  75.7\n",
      "-0.2153846153846154\n",
      "85.9  |  75.7\n",
      "-0.20769230769230768\n",
      "85.9  |  75.7\n",
      "-0.2\n",
      "85.9  |  75.7\n",
      "-0.1923076923076923\n",
      "85.9  |  75.7\n",
      "-0.18461538461538463\n",
      "85.9  |  75.7\n",
      "-0.1769230769230769\n",
      "85.9  |  75.7\n",
      "-0.16923076923076924\n",
      "85.9  |  75.7\n",
      "-0.16153846153846155\n",
      "85.9  |  76.4\n",
      "-0.15384615384615385\n",
      "85.9  |  76.8\n",
      "-0.14615384615384616\n",
      "85.9  |  76.8\n",
      "-0.13846153846153847\n",
      "85.9  |  76.8\n",
      "-0.13076923076923078\n",
      "85.9  |  77.5\n",
      "-0.12307692307692308\n",
      "85.9  |  77.9\n",
      "-0.11538461538461539\n",
      "85.9  |  78.6\n",
      "-0.1076923076923077\n",
      "85.9  |  79.3\n",
      "-0.1\n",
      "85.9  |  80.4\n",
      "-0.09230769230769231\n",
      "85.9  |  81.4\n",
      "-0.08461538461538462\n",
      "85.9  |  82.5\n",
      "-0.07692307692307693\n",
      "85.9  |  82.9\n",
      "-0.06923076923076923\n",
      "85.9  |  83.9\n",
      "-0.06153846153846154\n",
      "85.9  |  85.0\n",
      "-0.05384615384615385\n",
      "85.9  |  85.4\n",
      "-0.046153846153846156\n",
      "85.9  |  85.0\n",
      "-0.03846153846153849\n",
      "85.9  |  84.6\n",
      "-0.03076923076923077\n",
      "85.9  |  85.0\n",
      "-0.023076923076923106\n",
      "85.9  |  85.0\n",
      "-0.015384615384615385\n",
      "85.9  |  85.0\n",
      "-0.0076923076923077205\n",
      "85.9  |  85.7\n",
      "0.0\n",
      "85.9  |  86.1\n"
     ]
    }
   ],
   "source": [
    "for i in np.linspace(-0.3, 0.0, 40):\n",
    "    print(i)\n",
    "    print(get_aucroc(labels_eval, new_preds_val+i), \" | \", get_accuracy(labels_eval, new_preds_val+i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b67b3a9e-9838-45d5-a36c-1e25c28055a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.1  |  84.1\n",
      "79.8  |  91.0\n"
     ]
    }
   ],
   "source": [
    "x = -0.046153846153846156\n",
    "print(get_aucroc(labels_eval, new_preds_val+x), \" | \", get_accuracy(labels_eval, new_preds_val+x))\n",
    "print(get_aucroc(labels_test, new_preds_test+x), \" | \", get_accuracy(labels_test, new_preds_test+x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c173061-2a82-4f97-82ea-1ad99f6f8fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.linspace(-0.3, 0.0, 20):\n",
    "    # print(x)\n",
    "    print(get_aucroc(labels_test, new_preds_test+i), \" | \", get_accuracy(labels_test, new_preds_test+i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
