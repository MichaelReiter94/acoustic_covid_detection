{
    "parameters":
    "batch": [64]
    "lr"=[2e-3, 7e-4, 3e-4, 8e-5],  # lr of the output layer-the lr between in/output layer are linearly interpolated
    wd=[1e-4],  # weight decay regularization
    lr_decay=[0.99, 0.97],
    mixup_a=[0.2],  # alpha value to decide probability distribution of how much of each of the samples is used
    mixup_p=[0.8],  # probability of mix up being used at all
    use_augm_datasets=[True, False],
    shift=[True],
    sigma=[0.2],
    weighted_sampler=[True],  # whether to use a weighted random sampler to address the class imbalance
    class_weight=[1],  # factor for loss of the positive class to address class imbalance
    bag_size=[8],
    n_MIL_Neurons=[64],
    time_steps=[150],
    lr_in=[None],  # lr of the input layer - the lr between in/output layer are linearly interpolated
    dropout_p=[0.0, 0.15, 0.3],
    focal_loss=[0],
    # if focal_loss (gamma) == 0 it is the same as the BCE, increasing it makes it focus on harder examples.
    # If you go below, it learns more from well classified examples and ignores more badly classified ones
    min_quality=[1, 2]
    # audio quality is divided into 3 classes "0" being ba audio, "1" being medium and "2" premium quality.
    # quality "0" is usually already removed when creating the feature set to save memory
)
}